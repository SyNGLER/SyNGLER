{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SyNGLER Baseline Evaluation Demo\n",
    "\n",
    "This notebook demonstrates our comprehensive evaluation framework for network generation baselines. We evaluate four baselines (SyNGLER-Diff, SyNGLER-Res, GRAN, EDGE, VGAE) and ER on four datasets (DBLP, PolBlogs, Yelp, YouTube) using various network metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add utils to path\n",
    "sys.path.append('./evaluation')\n",
    "from utils import *\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "We configure the evaluation parameters including datasets, baselines, number of samples, and data paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "datasets = ['dblp', 'polblogs', 'yelp', 'youtube']\n",
    "baselines = ['diff', 'res', 'gran', 'edge', 'vgae', 'er']\n",
    "num_samples = 5  # Number of synthetic samples to evaluate per baseline\n",
    "\n",
    "# Paths\n",
    "data_root = \"../../datasets\"\n",
    "synthetic_root = \"../../synthetic\"\n",
    "\n",
    "print(f\"Datasets: {datasets}\")\n",
    "print(f\"Baselines: {baselines}\")\n",
    "print(f\"Number of samples per baseline: {num_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Real Data\n",
    "\n",
    "We load the real network datasets that will serve as ground truth for our evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load real datasets\n",
    "real_data = {}\n",
    "for dataset in datasets:\n",
    "    try:\n",
    "        real_data[dataset] = load_real_data(dataset, data_root)\n",
    "        print(f\"Loaded {dataset}: shape {real_data[dataset].shape}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading {dataset}: {e}\")\n",
    "        real_data[dataset] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Synthetic Data and Compute Metrics\n",
    "\n",
    "We load synthetic data from all baselines and compute comprehensive evaluation metrics for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results storage\n",
    "all_results = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    if real_data[dataset] is None:\n",
    "        print(f\"Skipping {dataset} - no real data available\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n=== Evaluating {dataset.upper()} ===\")\n",
    "    all_results[dataset] = {}\n",
    "    \n",
    "    for baseline in baselines:\n",
    "        print(f\"\\n--- {baseline.upper()} ---\")\n",
    "        \n",
    "        try:\n",
    "            # Load synthetic data\n",
    "            if baseline == 'er':\n",
    "                # Generate ER samples\n",
    "                synthetic_data = []\n",
    "                for i in range(num_samples):\n",
    "                    A_er, p_hat = er_resample_gnp(real_data[dataset], B=1, seed=42+i)\n",
    "                    synthetic_data.append(A_er)\n",
    "                print(f\"Generated {len(synthetic_data)} ER samples with p={p_hat:.4f}\")\n",
    "            else:\n",
    "                synthetic_data = load_synthetic_data(baseline, dataset, synthetic_root, num_samples)\n",
    "                print(f\"Loaded {len(synthetic_data)} synthetic samples\")\n",
    "            \n",
    "            if len(synthetic_data) == 0:\n",
    "                print(f\"No synthetic data found for {baseline}\")\n",
    "                continue\n",
    "                \n",
    "            # Compute metrics\n",
    "            metrics = compute_metrics(real_data[dataset], synthetic_data, device=device)\n",
    "            all_results[dataset][baseline] = metrics\n",
    "            \n",
    "            # Print summary\n",
    "            print(f\"Triangle Density: Real={metrics['triangle_density']['real']:.4f}, Syn={metrics['triangle_density']['synthetic_mean']:.4f}±{metrics['triangle_density']['synthetic_std']:.4f}\")\n",
    "            print(f\"Global Clustering: Real={metrics['global_clustering']['real']:.4f}, Syn={metrics['global_clustering']['synthetic_mean']:.4f}±{metrics['global_clustering']['synthetic_std']:.4f}\")\n",
    "            print(f\"Degree Centrality Energy Distance: {metrics['degree_centrality_energy']['energy_distance']:.4f}\")\n",
    "            print(f\"Eigenvalues Energy Distance: {metrics['eigenvalues_energy']['energy_distance']:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {baseline} for {dataset}: {e}\")\n",
    "            all_results[dataset][baseline] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Summary Tables\n",
    "\n",
    "We create comprehensive summary tables that compare baseline performance across all metrics and datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary tables for each metric\n",
    "def create_summary_table(metric_name, metric_key, datasets, baselines, all_results):\n",
    "    \"\"\"Create a summary table for a specific metric\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        if dataset not in all_results:\n",
    "            continue\n",
    "            \n",
    "        row = {'Dataset': dataset.upper()}\n",
    "        \n",
    "        for baseline in baselines:\n",
    "            if baseline in all_results[dataset] and all_results[dataset][baseline] is not None:\n",
    "                if metric_key in all_results[dataset][baseline][metric_name]:\n",
    "                    value = all_results[dataset][baseline][metric_name][metric_key]\n",
    "                    if isinstance(value, (int, float)):\n",
    "                        row[baseline.upper()] = f\"{value:.4f}\"\n",
    "                    else:\n",
    "                        row[baseline.upper()] = str(value)\n",
    "                else:\n",
    "                    row[baseline.upper()] = \"N/A\"\n",
    "            else:\n",
    "                row[baseline.upper()] = \"N/A\"\n",
    "        \n",
    "        data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Create tables for different metrics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY TABLES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Triangle Density\n",
    "print(\"\\n1. TRIANGLE DENSITY (Real Values)\")\n",
    "print(\"-\"*50)\n",
    "tri_density_table = create_summary_table('triangle_density', 'real', datasets, baselines, all_results)\n",
    "print(tri_density_table.to_string(index=False))\n",
    "\n",
    "# Global Clustering Coefficient\n",
    "print(\"\\n2. GLOBAL CLUSTERING COEFFICIENT (Real Values)\")\n",
    "print(\"-\"*50)\n",
    "gcc_table = create_summary_table('global_clustering', 'real', datasets, baselines, all_results)\n",
    "print(gcc_table.to_string(index=False))\n",
    "\n",
    "# Degree Centrality Energy Distance\n",
    "print(\"\\n3. DEGREE CENTRALITY ENERGY DISTANCE (Lower is Better)\")\n",
    "print(\"-\"*50)\n",
    "degree_energy_table = create_summary_table('degree_centrality_energy', 'energy_distance', datasets, baselines, all_results)\n",
    "print(degree_energy_table.to_string(index=False))\n",
    "\n",
    "# Eigenvalues Energy Distance\n",
    "print(\"\\n4. EIGENVALUES ENERGY DISTANCE (Lower is Better)\")\n",
    "print(\"-\"*50)\n",
    "eigenvals_energy_table = create_summary_table('eigenvalues_energy', 'energy_distance', datasets, baselines, all_results)\n",
    "print(eigenvals_energy_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Synthetic vs Real Comparison Tables\n",
    "\n",
    "We create detailed comparison tables that show synthetic vs real values with error analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison tables showing synthetic vs real values\n",
    "def create_comparison_table(metric_name, datasets, baselines, all_results):\n",
    "    \"\"\"Create a comparison table showing synthetic vs real values\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        if dataset not in all_results:\n",
    "            continue\n",
    "            \n",
    "        for baseline in baselines:\n",
    "            if baseline in all_results[dataset] and all_results[dataset][baseline] is not None:\n",
    "                if metric_name in all_results[dataset][baseline]:\n",
    "                    real_val = all_results[dataset][baseline][metric_name]['real']\n",
    "                    syn_mean = all_results[dataset][baseline][metric_name]['synthetic_mean']\n",
    "                    syn_std = all_results[dataset][baseline][metric_name]['synthetic_std']\n",
    "                    \n",
    "                    row = {\n",
    "                        'Dataset': dataset.upper(),\n",
    "                        'Baseline': baseline.upper(),\n",
    "                        'Real': f\"{real_val:.4f}\",\n",
    "                        'Synthetic': f\"{syn_mean:.4f}±{syn_std:.4f}\",\n",
    "                        'Difference': f\"{syn_mean - real_val:+.4f}\",\n",
    "                        'Relative_Error': f\"{((syn_mean - real_val) / real_val * 100):+.2f}%\"\n",
    "                    }\n",
    "                    data.append(row)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SYNTHETIC vs REAL COMPARISON\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Triangle Density Comparison\n",
    "print(\"\\n1. TRIANGLE DENSITY COMPARISON\")\n",
    "print(\"-\"*80)\n",
    "tri_density_comp = create_comparison_table('triangle_density', datasets, baselines, all_results)\n",
    "print(tri_density_comp.to_string(index=False))\n",
    "\n",
    "# Global Clustering Comparison\n",
    "print(\"\\n2. GLOBAL CLUSTERING COEFFICIENT COMPARISON\")\n",
    "print(\"-\"*80)\n",
    "gcc_comp = create_comparison_table('global_clustering', datasets, baselines, all_results)\n",
    "print(gcc_comp.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "We provide comprehensive visualizations to analyze baseline performance across different metrics and datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Baseline Performance Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Triangle Density Comparison\n",
    "ax1 = axes[0, 0]\n",
    "tri_density_data = []\n",
    "for dataset in datasets:\n",
    "    if dataset in all_results:\n",
    "        for baseline in baselines:\n",
    "            if baseline in all_results[dataset] and all_results[dataset][baseline] is not None:\n",
    "                real_val = all_results[dataset][baseline]['triangle_density']['real']\n",
    "                syn_val = all_results[dataset][baseline]['triangle_density']['synthetic_mean']\n",
    "                tri_density_data.append({\n",
    "                    'Dataset': dataset.upper(),\n",
    "                    'Baseline': baseline.upper(),\n",
    "                    'Real': real_val,\n",
    "                    'Synthetic': syn_val,\n",
    "                    'Error': abs(syn_val - real_val)\n",
    "                })\n",
    "\n",
    "if tri_density_data:\n",
    "    df_tri = pd.DataFrame(tri_density_data)\n",
    "    sns.barplot(data=df_tri, x='Dataset', y='Error', hue='Baseline', ax=ax1)\n",
    "    ax1.set_title('Triangle Density Error')\n",
    "    ax1.set_ylabel('Absolute Error')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Global Clustering Comparison\n",
    "ax2 = axes[0, 1]\n",
    "gcc_data = []\n",
    "for dataset in datasets:\n",
    "    if dataset in all_results:\n",
    "        for baseline in baselines:\n",
    "            if baseline in all_results[dataset] and all_results[dataset][baseline] is not None:\n",
    "                real_val = all_results[dataset][baseline]['global_clustering']['real']\n",
    "                syn_val = all_results[dataset][baseline]['global_clustering']['synthetic_mean']\n",
    "                gcc_data.append({\n",
    "                    'Dataset': dataset.upper(),\n",
    "                    'Baseline': baseline.upper(),\n",
    "                    'Real': real_val,\n",
    "                    'Synthetic': syn_val,\n",
    "                    'Error': abs(syn_val - real_val)\n",
    "                })\n",
    "\n",
    "if gcc_data:\n",
    "    df_gcc = pd.DataFrame(gcc_data)\n",
    "    sns.barplot(data=df_gcc, x='Dataset', y='Error', hue='Baseline', ax=ax2)\n",
    "    ax2.set_title('Global Clustering Error')\n",
    "    ax2.set_ylabel('Absolute Error')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Energy Distance Comparison\n",
    "ax3 = axes[1, 0]\n",
    "energy_data = []\n",
    "for dataset in datasets:\n",
    "    if dataset in all_results:\n",
    "        for baseline in baselines:\n",
    "            if baseline in all_results[dataset] and all_results[dataset][baseline] is not None:\n",
    "                degree_energy = all_results[dataset][baseline]['degree_centrality_energy']['energy_distance']\n",
    "                eigenvals_energy = all_results[dataset][baseline]['eigenvalues_energy']['energy_distance']\n",
    "                energy_data.append({\n",
    "                    'Dataset': dataset.upper(),\n",
    "                    'Baseline': baseline.upper(),\n",
    "                    'Degree_Energy': degree_energy,\n",
    "                    'Eigenvals_Energy': eigenvals_energy,\n",
    "                    'Total_Energy': degree_energy + eigenvals_energy\n",
    "                })\n",
    "\n",
    "if energy_data:\n",
    "    df_energy = pd.DataFrame(energy_data)\n",
    "    sns.barplot(data=df_energy, x='Dataset', y='Total_Energy', hue='Baseline', ax=ax3)\n",
    "    ax3.set_title('Total Energy Distance (Lower is Better)')\n",
    "    ax3.set_ylabel('Energy Distance')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Combined Performance\n",
    "ax4 = axes[1, 1]\n",
    "combined_data = []\n",
    "for dataset in datasets:\n",
    "    if dataset in all_results:\n",
    "        for baseline in baselines:\n",
    "            if baseline in all_results[dataset] and all_results[dataset][baseline] is not None:\n",
    "                tri_error = abs(all_results[dataset][baseline]['triangle_density']['synthetic_mean'] - \n",
    "                               all_results[dataset][baseline]['triangle_density']['real'])\n",
    "                gcc_error = abs(all_results[dataset][baseline]['global_clustering']['synthetic_mean'] - \n",
    "                               all_results[dataset][baseline]['global_clustering']['real'])\n",
    "                total_energy = (all_results[dataset][baseline]['degree_centrality_energy']['energy_distance'] + \n",
    "                               all_results[dataset][baseline]['eigenvalues_energy']['energy_distance'])\n",
    "                combined_score = tri_error + gcc_error + total_energy\n",
    "                combined_data.append({\n",
    "                    'Dataset': dataset.upper(),\n",
    "                    'Baseline': baseline.upper(),\n",
    "                    'Combined_Score': combined_score\n",
    "                })\n",
    "\n",
    "if combined_data:\n",
    "    df_combined = pd.DataFrame(combined_data)\n",
    "    sns.barplot(data=df_combined, x='Dataset', y='Combined_Score', hue='Baseline', ax=ax4)\n",
    "    ax4.set_title('Combined Performance Score (Lower is Better)')\n",
    "    ax4.set_ylabel('Combined Score')\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking Analysis\n",
    "\n",
    "We perform comprehensive ranking analysis to identify the best-performing baselines across all datasets and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ranking analysis\n",
    "def create_ranking_table(datasets, baselines, all_results):\n",
    "    \"\"\"Create a ranking table based on overall performance\"\"\"\n",
    "    ranking_data = []\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        if dataset not in all_results:\n",
    "            continue\n",
    "            \n",
    "        baseline_scores = {}\n",
    "        \n",
    "        for baseline in baselines:\n",
    "            if baseline in all_results[dataset] and all_results[dataset][baseline] is not None:\n",
    "                # Calculate composite score (lower is better)\n",
    "                score = 0\n",
    "                \n",
    "                # Triangle density error\n",
    "                real_tri = all_results[dataset][baseline]['triangle_density']['real']\n",
    "                syn_tri = all_results[dataset][baseline]['triangle_density']['synthetic_mean']\n",
    "                tri_error = abs(syn_tri - real_tri) / real_tri if real_tri > 0 else 0\n",
    "                score += tri_error\n",
    "                \n",
    "                # Global clustering error\n",
    "                real_gcc = all_results[dataset][baseline]['global_clustering']['real']\n",
    "                syn_gcc = all_results[dataset][baseline]['global_clustering']['synthetic_mean']\n",
    "                gcc_error = abs(syn_gcc - real_gcc) / real_gcc if real_gcc > 0 else 0\n",
    "                score += gcc_error\n",
    "                \n",
    "                # Energy distances (normalized)\n",
    "                degree_energy = all_results[dataset][baseline]['degree_centrality_energy']['energy_distance']\n",
    "                eigenvals_energy = all_results[dataset][baseline]['eigenvalues_energy']['energy_distance']\n",
    "                score += degree_energy + eigenvals_energy\n",
    "                \n",
    "                baseline_scores[baseline] = score\n",
    "        \n",
    "        # Rank baselines for this dataset\n",
    "        sorted_baselines = sorted(baseline_scores.items(), key=lambda x: x[1])\n",
    "        \n",
    "        for rank, (baseline, score) in enumerate(sorted_baselines, 1):\n",
    "            ranking_data.append({\n",
    "                'Dataset': dataset.upper(),\n",
    "                'Rank': rank,\n",
    "                'Baseline': baseline.upper(),\n",
    "                'Score': f\"{score:.4f}\"\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(ranking_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RANKING ANALYSIS (Lower Score = Better Performance)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "ranking_table = create_ranking_table(datasets, baselines, all_results)\n",
    "print(ranking_table.to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"RANKING SUMMARY\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "rank_counts = ranking_table['Baseline'].value_counts()\n",
    "print(\"\\nNumber of times each baseline achieved rank 1:\")\n",
    "for baseline in rank_counts.index:\n",
    "    count = len(ranking_table[(ranking_table['Baseline'] == baseline) & (ranking_table['Rank'] == 1)])\n",
    "    print(f\"{baseline}: {count} times\")\n",
    "\n",
    "print(\"\\nAverage rank by baseline:\")\n",
    "avg_ranks = ranking_table.groupby('Baseline')['Rank'].mean().sort_values()\n",
    "for baseline, avg_rank in avg_ranks.items():\n",
    "    print(f\"{baseline}: {avg_rank:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "\n",
    "We save all evaluation results to CSV files for further analysis and reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV files\n",
    "output_dir = \"./results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save summary tables\n",
    "tri_density_table.to_csv(os.path.join(output_dir, \"triangle_density_summary.csv\"), index=False)\n",
    "gcc_table.to_csv(os.path.join(output_dir, \"global_clustering_summary.csv\"), index=False)\n",
    "degree_energy_table.to_csv(os.path.join(output_dir, \"degree_centrality_energy_summary.csv\"), index=False)\n",
    "eigenvals_energy_table.to_csv(os.path.join(output_dir, \"eigenvalues_energy_summary.csv\"), index=False)\n",
    "\n",
    "# Save comparison tables\n",
    "tri_density_comp.to_csv(os.path.join(output_dir, \"triangle_density_comparison.csv\"), index=False)\n",
    "gcc_comp.to_csv(os.path.join(output_dir, \"global_clustering_comparison.csv\"), index=False)\n",
    "\n",
    "# Save ranking table\n",
    "ranking_table.to_csv(os.path.join(output_dir, \"ranking_analysis.csv\"), index=False)\n",
    "\n",
    "print(f\"\\nResults saved to {output_dir}/\")\n",
    "print(\"Files created:\")\n",
    "for file in os.listdir(output_dir):\n",
    "    print(f\"  - {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Our evaluation framework provides comprehensive assessment of network generation baselines using multiple metrics:\n",
    "\n",
    "1. **Triangle Density**: Measures the clustering in the network\n",
    "2. **Global Clustering Coefficient**: Measures the overall transitivity\n",
    "3. **Degree Centrality Energy Distance**: Measures the distribution of node degrees\n",
    "4. **Eigenvalues Energy Distance**: Measures the spectral properties\n",
    "\n",
    "The results demonstrate how well each baseline captures the structural properties of the real networks. Lower energy distances and smaller absolute errors indicate better performance. Our framework enables systematic comparison and ranking of different network generation approaches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}